Chapter 3 Notes:

There is no perfect ML algorithm for every scenario. The best strategy often
uses a handful of algorithms to select the best model for a particular problem.

5 steps for training a ML algorithm:
  1. selection of features (pre-processing)
  2. choosing a performance metric
  3. choosing a classifier and optimization algorithm
  4. evaluating the performance of the model
  5. tuning the algorithm
  
Perceptrons fail to converge when the classes are not perfectly linearly 
separable. Since the weights are continuously being updated there is always
at least one misclassified sample present in each epoch. Changing the learning
rate and max epoch won't allow convergence with this classifier in most 
scenarios like the Iris data set. 



Logistic Regression:
(model of classification, not regression)

Logistic Regression is a classification model is easy to implement and
performs well on linearly separable classes. While it's like the Perceptron
and Adaline in that it's a linear model for binary classification, it also
has the advantage of being used for multiclass classification using the OvR
technqiue.

Reminder from Chapter 2 on OvR:
One-vs-All (OvA) or One-vs-Rest (OvR): technique used to extend binary 
classifier to multi-class problems. Train one classifier per class where the 
particular class is positive and all others are negative. If we classify a 
new data sample, we use our n classifiers and assign the class label with the
highest relation to a particular sample. 

Odds Ratio: odds in favor of a particular event, written as p/1-p, where p
stands for the probability of the positive event (the event we want to predict).

Logit function: logit(p) = log(p/1-p)
 
The logit function is the logarithm of the odds ratio. Takes input values
in the range 0-1 and transforms them to values over the entire real number
range. Shows a linear relationship between feature values and log-odds.

Logit( p(y=1 | x) ) = E(i) w(i)x(i)

p(y=1 | x) is the conditional probability that a particular sample belongs
to class 1 given it's features x.

Predicting the probability that a certain sample belongs to a particular class
is the inverse form of the logit function, or the logistic function or sigmoid
function due to it's characteristic S-shape.

o(z) = 1 / 1 + E^(-z) = e^x / e^x + 1

z = E(i) w(i)x(i)
z is the net input or the linear combination of weights and sample features.

Adaline uses the identity function as the activation function, and in logistic
regression the sigmoid function is the activation function. The predicted
probability can be converted into a binary outcome via a quantizer, where the
threshold is the y-intercept of the sigmoid function.

Applications of Logistic Regression:
Logistic regression is used in weather forecasting for predicting the chance
of a particular type of weather. It can also be used to predict that a patient
has a particular disease given certain symptoms. 

Overfitting and underfitting is common problem in ML, where a model performs 
well on training data, but not on the unseen test data. In these cases the 
model is too complex or not complex enough to classify the pattern in the
training data.

Regularization is a useful method to handle collinearity (high correlation
among features), filter out noise, and prevent overfitting. Basically, 
regularization introduces additional information bias to penalize extreme
parameter weights. L2 Regularization is an example. Features need to be
comparable weights (through standardization and other feature scaling methods)
in order for regularization to be effective. 

In order to use, add regularization parameter to cost function.

Lambda (regularization parameter) can be adjusted to increase regularization
strength. For example, in the Logistic Regression class in scikit-learn, 
C = 1/lambda. In this case, the regularization parameter is decreased, which
increases the regularization strength.


Support Vector Machines (SVM)

SVMs is another widely used learning algorithm. Considered an extension
from the perceptron algorithm. The optimization objective is to maximize the
margin, which is defined as the distance between the separating hyperplane
(decision boundary) and the training samples that are closest to this
hyperplane, which are called support vectors.

Decision boundaries with large margins tend to have a lower generalization error
whereas models with small margins tend to overfit more.

Using C and a slack variable the weight of the margin can be tuned, in order
to tune the bias-variance trade-off.

Logistic Regression and SVMs often yield similar results. LR tries to maximize
the conditional likelihood of the training data, so it gets more outliers.
SVMs care about points closest to the decision boundary (support vectors). 
However, LR can implemented more easily and can easily updated, which is useful
when streaming in data.

SVMs can be easily kernelized to solve non-linear classification problems.
Kernel methods create nonlinear combinations of the original features to project
them onto a higher dimensional space via a mapping function. 

One problem with the mapping function is that construction of the new features
is computationally expensive, especially for high dimensional data. 

Kernel function replaces the dot product.

Radial Basis Function kernel (RBF kernel) or Gaussian kernel is widely used.

The term kernel can be interpreted as a similarity function between a pair of
samples.


Decision Tree Learning

DTs are great models if we care about interpretability, meaning we can break 
down our data by making decisions based on a series of questions.

Example:
          Work to do?
      Y /        N  \
      Stay In       Outlook?
                   s/  c|  r\ 
              beach   run    friends busy?
                              Y /      N \
                            Stay In     Go to movies

Based on the features of a training set, the DT model learns a series of
questions to infer the class labels of the samples.

With the DT algorithm, starting at the root, split the data on the feature
that results in the largest information gain (IG). Iterate the splitting
process at each child node until the leaves belong to the same class. This can
result in a deep tree with many nodes, which may cause overfitting, so the tree
is pruned by setting a max limit for the depth of the tree.

Scikit-learn has binary decision trees (BDT) to reduce combinational search 
space.

3 impurity measures or splitting criteria for BDTs:
Gini impurity
entropy
classification error

Gini impurity: maximal if classes are perfectly mixed

entropy: 0 if all samples at a node belong to the same class, and 1 when
we have a uniform class distribution. Entropy attempts to maximize the mutual
information in the tree.

note:
Gini and entropy yield similar results. Better to try pruning techniques rather
than focus evaluating trees based on different criteria.

classification error: useful for pruning, but not growing a DT, since it is
less sensitive to changes in the class probabilities of the nodes.

DTs can build complex decision boundaries by dividing the feature space into
rectangles. Deeper the decision tree, deeper the decision boundary becomes, 
which can cause overfitting.

feature scaling is not a requirement for decision tree algorithms.

scikit-learn can export decision trees as .dot files (see page 89 for details)


Random Forests (RF)
Popular due to good classification performance, scalability, and ease of use.

Thought of as an ensemble of decision trees.

Combine weak learners to create a strong learner that has better generalization
error and is less susceptible to overfitting.

Algorithm:
  1. randomly choose n samples from the training set with replacement
  2. Grow a decision tree from sample. At each node:
    1. select random 'd' features without replacement
    2. split the node using the feature the provides the best split according
      to the objective function, by maximizing the IG
  3. repeat steps 1-2 k times
  4. Aggregate the prediction by each tree to assign the class label by majority
    vote. (chapter 7 details this more)
    
Difference between decision trees is that not all features are being evaluated
in step 2, only a random sample subset of those features. However, they don't 
offer the same level of interpretability as decision trees. 

RF don't need  to focus on good parameter choices. 
Don't need to prune
We only care about k, the number of trees
More trees the better, but at the expense of an increased computation cost.




K-Nearest Neighbors (KNN) - lazy learning algorithm

last supervised learning algorithm in chapter 3

lazy, because it doesn't learn from a discriminative function from the training
data, but memorizes the training dataset instead.

Algorithm:
  1. Choose the number of k and a distance metric
  2. Find the k nearest neighbors of the sample that we want to classify
  3. Assign the class label by majority vote
  
Classifier adapts as we collect new training data. More costly as the dataset
grows. KD-tree implementations help efficiency. 

Needs:
The right choice of k is crucial between underfitting and overfitting. 
Appropriate distance metric (most often Euclidean)

Minkowski distance is just a generalization of Euclidean and Manhattan distance.
(formula on page 95)
p = 1, Manhattan
p = 2, Euclidean

Avoid the "Curse of Dimensionality"
feature selection and dimension reduction are good for KNN and decision trees.

                       
                            
 












  